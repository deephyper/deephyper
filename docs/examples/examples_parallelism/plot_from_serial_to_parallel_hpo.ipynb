{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# From Sequential to Massively-Parallel Bayesian Optimization\n\n**Author(s)**: Romain Egele.\n\nIn this example you will learn about the advantages of parallel over sequential\nevaluations with Bayesian optimization. \n\nWe start by defining a black-box ``run``-function that implements the Ackley function:\n\n<img src=\"https://www.sfu.ca/~ssurjano/ackley.png\" width=\"400\" alt=\"Ackley Function in 2D\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Import statements\nimport time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom deephyper.analysis import figure_size\nfrom deephyper.analysis.hpo import plot_search_trajectory_single_objective_hpo\nfrom deephyper.analysis.hpo import plot_worker_utilization\nfrom deephyper.evaluator import Evaluator, profile\nfrom deephyper.evaluator.callback import TqdmCallback\nfrom deephyper.hpo import HpProblem, CBO, RandomSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the Ackley function:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Ackley function\ndef ackley(x, a=20, b=0.2, c=2 * np.pi):\n    d = len(x)\n    s1 = np.sum(x**2)\n    s2 = np.sum(np.cos(c * x))\n    term1 = -a * np.exp(-b * np.sqrt(s1 / d))\n    term2 = -np.exp(s2 / d)\n    y = term1 + term2 + a + np.exp(1)\n    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use the ``time.sleep`` function to simulate a budget of 2 secondes of execution in average \nwhich helps illustrate the advantage of parallel evaluations. The ``@profile`` decorator is useful \nto collect starting/ending time of the ``run``-function execution which help us know exactly when \nwe are inside the black-box. This decorator is necessary when profiling the worker utilization. When \nusing this decorator, the ``run``-function will return a dictionnary with 2 new keys ``\"timestamp_start\"`` \nand ``\"timestamp_end\"``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@profile\ndef run_ackley(config, sleep_loc=2, sleep_scale=0.5):\n    # to simulate the computation of an expensive black-box\n    if sleep_loc > 0:\n        t_sleep = np.random.normal(loc=sleep_loc, scale=sleep_scale)\n        t_sleep = max(t_sleep, 0)\n        time.sleep(t_sleep)\n\n    x = np.array([config[k] for k in config if \"x\" in k])\n    x = np.asarray_chkfinite(x)  # ValueError if any NaN or Inf\n    return -ackley(x)  # maximisation is performed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define the variable(s) we want to optimize. For this problem we\noptimize Ackley in a N-dimensional search space. Each dimension in the continuous range\n[-32.768, 32.768]. The true minimum is located at ``(0, ..., 0)``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nb_dim = 5\nproblem = HpProblem()\nfor i in range(nb_dim):\n    problem.add_hyperparameter((-32.768, 32.768), f\"x{i}\")\nproblem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define some default search parameters for the Centralized Bayesian Optimization (CBO) algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search_kwargs = {\n    \"multi_point_strategy\": \"qUCBd\", # Multi-point strategy for asynchronous batch generations (explained later)\n    \"acq_optimizer\": \"ga\", # Use continuous Genetic Algorithm for the acquisition function optimizer\n    \"filter_duplicated\": False, # Deactivate filtration of duplicated new points\n    \"random_state\": 42, # Random seed\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define the time budget for the optimization. We will compare the performance of a sequential\nsearch with a parallel search for the same time budget. The time budget is defined in seconds.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "timeout = 60 # 1 minute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define the sequential Bayesian optimization search.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sequential_search = CBO(problem, run_ackley, **search_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The previously simplified definition of the search is equivalent to the following:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sequential_evaluator = Evaluator.create(\n    run_ackley,\n    method=\"thread\",  # For synchronous function defintion relying on the GIL or I/O bound tasks\n    method_kwargs={\n        \"num_workers\": 1, \n        \"callbacks\": [TqdmCallback(\"Sequential BO:\")]\n    },\n)\nsequential_search = CBO(problem, sequential_evaluator, **search_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a utility function to preprocess our results before plotting.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def preprocess_results(results):\n    results = results.dropna().copy()\n    offset = results[\"m:timestamp_start\"].min()\n    results[\"m:timestamp_start\"] -= offset\n    results[\"m:timestamp_end\"] -= offset\n    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Where we use the ``\"thread\"``-evaluator with a single worker and use the ``TqdmCallback`` to display\na progress bar during the search. \n\nWe can now run the sequential search for 2 minutes. The call to the ``search``-method will return a\nDataFrame with the results of the search.\n\nIf this step is executed multiple times without creating a new search the results will be accumulated in the same DataFrame.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = {}\nresults[\"sequential\"] = preprocess_results(sequential_search.search(timeout=timeout))\nresults[\"sequential\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each row of the DataFrame corresponds to an evaluation of the ``run``-function. The DataFrame contains the following columns:\n- ``\"p:*\"``: The parameters of the search space.\n- ``\"objective\"``: The objective value returned by the evaluation.\n- ``\"job_id\"``: The id of the evaluation in increasing order of job creation.\n- ``\"job_status\"``: The status of the evaluation (e.g., \"DONE\", \"CANCELLED\").\n- ``\"m:timestamp_submit/gather\"``: The submition and gathering times of the evaluation by the ``Evaluator`` (includes overheads).\n- ``\"m:timestamp_start/end\"``: The starting and ending time of the evaluation.\n\nWe can now plot the results of the sequential search. The first plot shows the evolution of the objective.\nThe second plot shows the utilization of the worker over time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Plot search trajectory and worker utilization\nfig, axes = plt.subplots(\n        nrows=2,\n        ncols=1,\n        sharex=True,\n        figsize=figure_size(width=600),\n        tight_layout=True,\n    )\n\n_ = plot_search_trajectory_single_objective_hpo(\n    results[\"sequential\"], mode=\"min\", x_units=\"seconds\", ax=axes[0]\n)\n\n_ = plot_worker_utilization(\n    results[\"sequential\"], num_workers=1, profile_type=\"start/end\", ax=axes[1]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we can create a parallel evaluator with 100 workers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parallel_evaluator = Evaluator.create(\n    run_ackley,\n    method=\"thread\",\n    method_kwargs={\n        \"num_workers\": 100, # For the parallel evaluations\n        \"callbacks\": [TqdmCallback(\"Parallel BO:\")]\n    },\n)\nparallel_search = CBO(problem, parallel_evaluator, **search_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The parallel search is executed for 1 minute.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results[\"parallel\"] = preprocess_results(parallel_search.search(timeout=timeout))\nresults[\"parallel\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It can be surprising to see in the results that the last lines have ``\"job_status\"`` set to \"CANCELLED\" but\nstill have an objective value. This is due to the fact that the cancellation of a job is asynchronous and already scheduled Asyncio tasks are therefore executed. When the timeout is reached the jobs created by the \"thread\" method jobs cannot be directly killed but rather their ``job.status`` is updated to ``\"CANCELLING\"`` and the user-code is responsible for checking the status of the job and interrupting the execution. This is why the objective value is still present in the results. This behavior is different from the \"process\" method where the jobs are killed directly.\n\nWe can now plot the results of the parallel search. The first plot shows the evolution of the objective.\nThe second plot shows the utilization of the worker over time.\n\nWe can see that the parallel search is able to evaluate a lot more points in the same time budget. This also\nallows the algorithm to explore more of the search space and potentially find better solutions.\nThe utilization plot shows that the workers are used efficiently in the parallel search (above 80%).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Plot search trajectory and worker utilization\nfig, axes = plt.subplots(\n        nrows=2,\n        ncols=1,\n        sharex=True,\n        figsize=figure_size(width=600),\n        tight_layout=True,\n    )\n\n_ = plot_search_trajectory_single_objective_hpo(\n    results[\"parallel\"], mode=\"min\", x_units=\"seconds\", ax=axes[0]\n)\n\n_ = plot_worker_utilization(\n    results[\"parallel\"], num_workers=1, profile_type=\"start/end\", ax=axes[1]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we compare both search with the execution time is used as the x-axis.\nThe advantage of parallelism is clearly visible by the difference in the number of evaluations and in objective.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Plot search trajectories\nfig, ax = plt.subplots(figsize=figure_size(width=600), tight_layout=True)\n\nfor i, (strategy, df) in enumerate(results.items()):\n    plot_search_trajectory_single_objective_hpo(\n        df,\n        show_failures=False,\n        mode=\"min\",\n        x_units=\"seconds\",\n        ax=ax,\n        label=strategy,\n        plot_kwargs={\"color\": f\"C{i}\"},\n        scatter_success_kwargs={\"color\": f\"C{i}\"},\n    )\n\n_ = ax.set_xlabel(\"Time (sec.)\")\n_ = ax.set_ylabel(\"Objective\")\n_ = ax.set_yscale(\"log\")\n_ = ax.grid(visible=True, which=\"minor\", linestyle=\":\")\n_ = ax.grid(visible=True, which=\"major\", linestyle=\"-\")\n_ = ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, one could compare to a random search to see if the overheads of the parallel Bayesian optimization are worth it (i.e., the cost of fitting and optimizing the surrogate model).\nThe evaluator is defined similarly to the one used for the parallel Bayesian optimization search:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parallel_evaluator = Evaluator.create(\n    run_ackley,\n    method=\"thread\",\n    method_kwargs={\n        \"num_workers\": 100, # For the parallel evaluations\n        \"callbacks\": [TqdmCallback(\"Random Search:\")]\n    },\n)\nrandom_search = RandomSearch(problem, parallel_evaluator, random_state=search_kwargs[\"random_state\"])\nresults[\"random\"] = preprocess_results(random_search.search(timeout=timeout))\nresults[\"random\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The number of evaluations of the random search is higher than the parallel Bayesian optimization search.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"Number of evaluations for the parallel Bayesian optimization: {len(results['parallel'])}\")\nprint(f\"Number of evaluations for the random search: {len(results['random'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The utilization of the worker is confirmed to be near 100% for the random search.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Plot search trajectory and worker utilization\nfig, axes = plt.subplots(\n        nrows=2,\n        ncols=1,\n        sharex=True,\n        figsize=figure_size(width=600),\n        tight_layout=True\n    )\n\n_ = plot_search_trajectory_single_objective_hpo(\n    results[\"random\"], mode=\"min\", x_units=\"seconds\", ax=axes[0]\n)\n\n_ = plot_worker_utilization(\n    results[\"random\"], num_workers=1, profile_type=\"start/end\", ax=axes[1]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, the objective value of the parallel Bayesian optimization search is significantly better than the random search.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Plot search trajectories\nfig, ax = plt.subplots(figsize=figure_size(width=600), tight_layout=True)\nlabels = {\n    \"random\": \"Parallel Random Search\",\n    \"sequential\": \"Sequential Bayesian Optimization\",\n    \"parallel\": \"Parallel Bayesian Optimization\",\n    }\nfor i, (key, label) in enumerate(labels.items()):\n    df = results[key]\n    _ = plot_search_trajectory_single_objective_hpo(\n        df,\n        show_failures=False,\n        mode=\"min\",\n        x_units=\"seconds\",\n        ax=ax,\n        label=label,\n        plot_kwargs={\"color\": f\"C{i}\"},\n        scatter_success_kwargs={\"color\": f\"C{i}\", \"alpha\": 0.5},\n    )\n\n_ = ax.set_xlabel(\"Time (sec.)\")\n_ = ax.set_ylabel(\"Objective\")\n_ = ax.set_yscale(\"log\")\n_ = ax.grid(visible=True, which=\"minor\", linestyle=\":\")\n_ = ax.grid(visible=True, which=\"major\", linestyle=\"-\")\n_ = ax.legend()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}