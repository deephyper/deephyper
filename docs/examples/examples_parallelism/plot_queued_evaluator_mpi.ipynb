{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Queued Evaluator with MPI\n\n**Author(s)**: Romain Egele, Brett Eiffert.\n\nIn this example, you will learn how to use a queued ProcessPoolEvaluator with an mpi run function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Import statements\nimport subprocess\n\nfrom deephyper.evaluator import (\n    LokyEvaluator,\n    parse_subprocess_result,\n    profile,\n    queued,\n)\nfrom deephyper.evaluator.callback import TqdmCallback\nfrom deephyper.hpo import CBO, HpProblem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run function using MPI\n\nUsed by the main function to fork and manage mpi processes within the evaluator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@profile\ndef run_mpi_exe(job, dequed=None):\n    x = job.parameters[\"x\"]\n\n    # The format of the print \"DH-OUTPUT:(.+)\\n\" is strict if you use parse_suprocess_result\n    command = f\"mpirun -np {len(dequed)} echo DH-OUTPUT:{x}\\n\"\n    completed_process = subprocess.run(command.split(), capture_output=True)\n    objective = parse_subprocess_result(completed_process)\n\n    # In the results.csv a new `m:dequed` will show the passed dequed values.\n    return {\"objective\": objective, \"metadata\": {}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\nThe problem is defined with basic hyperparameters for a straightforward example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "problem = HpProblem()\nproblem.add_hyperparameter((0.0, 10.0), \"x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Variables used for selecting the number of workers to execute the pool of mpi workers.\nThese are defined for show and can be run in a multi-node setup or on a single node or local machine.\nNumber of processes spawned = num_nodes / num_nodes_per_task\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Local machine or single node\nnum_nodes = 1\nnum_nodes_per_task = 1\n# Multi-node setup\n#num_nodes = 10\n#num_nodes_per_task = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parallel Processing\n\nWe define a main function which sets up an mpi enabled evaluator object to be used to evaluate the model in parallel. Tasks are spawned in the run_mpi_exe function that was defined earlier and queued in a ``LokyEvaluator``.\n\nUsing the evaluator (``LokyEvaluator``), the search is performed for a user defined number of iterations (50).\n``LokyEvaluator`` was chosen over other deephyper evaluators ``ProcessPoolEvaluator`` and ``ThreadPoolEvaluator`` due to the preference of running MPI processes and the necessity of argument based process spawning required by notebook-style runtimes.\n To read more about the evaluator backend options and how to choose the best on for a specific use case, go to (coming soon). \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def main():\n    evaluator = queued(LokyEvaluator)(\n        run_function=run_mpi_exe,\n        num_workers=num_nodes // num_nodes_per_task,\n        callbacks=[TqdmCallback()],\n        queue=[node_id for node_id in range(num_nodes)],\n        queue_pop_per_task=num_nodes_per_task,\n    )\n\n    print(f\"Evaluator uses {evaluator.num_workers} workers\")\n\n    search = CBO(problem, evaluator, log_dir=\"log_queued_evaluator\")\n    \n    search.search(max_evals=50)\n\nif __name__ == \"__main__\":\n    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}