{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# From Sequential to Massively-Parallel Bayesian Optimization\n\n**Author(s)**: Romain Egele.\n\nThis example demonstrates the advantages of parallel evaluations over sequential\nevaluations with Bayesian optimization. We start by defining a black-box ``run``-function that \nimplements the Ackley function:\n\n<img src=\"https://www.sfu.ca/~ssurjano/ackley.png\" width=\"400\" alt=\"Ackley Function in 2D\">\n\nTo help illustrate the parallelization gain, we will simulate a computational cost\nby using ``time.sleep``. We also use the ``@profile`` decorator to collect starting/ending\ntimes of each call to the ``run``-function. When using this decorator, the ``run``-function will\nreturn a dictionnary including ``\"metadata\"`` with 2 new keys ``\"timestamp_start\"`` and\n``\"timestamp_end\"``. The ``run``-function is defined in a separate Python module\nfor better serialization (through ``pickle``) in case other parallel backends such as ``\"process\"`` would be used\n\n.. literalinclude:: ../../examples/black_box_util.py\n   :language: python\n\nAfter defining the ``run``-function we can continue with the definition of our optimization script:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import black_box_util as black_box\nimport matplotlib.pyplot as plt\n\nfrom deephyper.analysis import figure_size\nfrom deephyper.analysis.hpo import plot_search_trajectory_single_objective_hpo\nfrom deephyper.analysis.hpo import plot_worker_utilization\nfrom deephyper.evaluator import Evaluator\nfrom deephyper.evaluator.callback import TqdmCallback\nfrom deephyper.hpo import HpProblem, CBO, RandomSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define the variable(s) we want to optimize. For this problem we\noptimize Ackley in a N-dimensional search space. Each dimension in the continuous range\n[-32.768, 32.768]. The true minimum is located at ``(0, ..., 0)``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nb_dim = 5\nproblem = HpProblem()\nfor i in range(nb_dim):\n    problem.add_hyperparameter((-32.768, 32.768), f\"x{i}\")\nproblem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define some default search parameters for the Centralized Bayesian Optimization (CBO) algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search_kwargs = {\n    \"n_initial_points\": 2 * nb_dim + 1, # Number of initial random points\n    \"surrogate_model\": \"ET\", # Use Extra Trees as surrogate model\n    \"surrogate_model_kwargs\": {\n        \"n_estimators\": 25, # Relatively small number of trees in the surrogate to make it \"fast\" \n        \"min_samples_split\": 8, # Larger number to avoid small leaf nodes (smoothing the response)\n    },\n    \"multi_point_strategy\": \"qUCBd\", # Multi-point strategy for asynchronous batch generations (explained later)\n    \"acq_optimizer\": \"ga\", # Use continuous Genetic Algorithm for the acquisition function optimizer\n    \"acq_optimizer_freq\": 1, # Frequency of the acquisition function optimizer (1 = each new batch generation) increasing this value can help amortize the computational cost of acquisition function optimization\n    \"filter_duplicated\": False, # Deactivate filtration of duplicated new points\n    \"kappa\": 10.0, # Initial value of exploration-exploitation parameter for the acquisition function\n    \"scheduler\": { # Scheduler for the exploration-exploitation parameter \"kappa\"\n        \"type\": \"periodic-exp-decay\", # Periodic exponential decay \n        \"period\": 50, # Period over which the decay is applied. It is useful to escape local solutions.\n        \"kappa_final\": 0.001 # Value of kappa at the end of each \"period\"\n    },\n    \"random_state\": 42, # Random seed\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define the time budget for the optimization. We will compare the performance of a sequential\nsearch with a parallel search for the same time budget. The time budget is defined in seconds.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "timeout = 60 # 1 minute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define the sequential Bayesian optimization search.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sequential_search = CBO(problem, black_box.run_ackley, **search_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The previously simplified definition of the search is equivalent to the following:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sequential_evaluator = Evaluator.create(\n    black_box.run_ackley,\n    method=\"thread\",  # For synchronous function defintion relying on the GIL or I/O bound tasks\n    method_kwargs={\n        \"num_workers\": 1, \n        \"callbacks\": [TqdmCallback()]\n    },\n)\nsequential_search = CBO(problem, sequential_evaluator, **search_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Where we use the ``\"thread\"``-evaluator with a single worker and use the ``TqdmCallback`` to display\na progress bar during the search. \n\nWe can now run the sequential search for 2 minutes. The call to the ``search``-method will return a\nDataFrame with the results of the search.\n\nIf this step is executed multiple times without creating a new search the results will be accumulated in the same DataFrame.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = {}\nresults[\"sequential\"] = sequential_search.search(timeout=timeout)\noffset = results[\"sequential\"][\"m:timestamp_start\"].min()\nresults[\"sequential\"][\"m:timestamp_end\"] -= offset\nresults[\"sequential\"][\"m:timestamp_start\"] -= offset\nresults[\"sequential\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each row of the DataFrame corresponds to an evaluation of the ``run``-function. The DataFrame contains the following columns:\n- ``\"p:*\"``: The parameters of the search space.\n- ``\"objective\"``: The objective value returned by the evaluation.\n- ``\"job_id\"``: The id of the evaluation in increasing order of job creation.\n- ``\"job_status\"``: The status of the evaluation (e.g., \"DONE\", \"CANCELLED\").\n- ``\"m:timestamp_submit/gather\"``: The submition and gathering times of the evaluation by the ``Evaluator`` (includes overheads).\n- ``\"m:timestamp_start/end\"``: The starting and ending time of the evaluation.\n\nWe can now plot the results of the sequential search. The first plot shows the evolution of the objective.\nThe second plot shows the utilization of the worker over time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(\n        nrows=2,\n        ncols=1,\n        sharex=True,\n        figsize=figure_size(width=600),\n    )\n\nplot_search_trajectory_single_objective_hpo(\n    results[\"sequential\"], mode=\"min\", x_units=\"seconds\", ax=axes[0]\n)\n\nplot_worker_utilization(\n    results[\"sequential\"], num_workers=1, profile_type=\"start/end\", ax=axes[1]\n)\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we can create a parallel evaluator with 100 workers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parallel_evaluator = Evaluator.create(\n    black_box.run_ackley,\n    method=\"thread\",\n    method_kwargs={\n        \"num_workers\": 100, # For the parallel evaluations\n        \"callbacks\": [TqdmCallback()]\n    },\n)\nparallel_search = CBO(problem, parallel_evaluator, **search_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The parallel search is executed for 1 minute.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results[\"parallel\"] = parallel_search.search(timeout=timeout)\noffset = results[\"parallel\"][\"m:timestamp_start\"].min()\nresults[\"parallel\"][\"m:timestamp_start\"] -= offset \nresults[\"parallel\"][\"m:timestamp_end\"] -= offset \nresults[\"parallel\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It can be surprising to see in the results that the last lines have ``\"job_status\"`` set to \"CANCELLED\" but\nstill have an objective value. This is due to the fact that the cancellation of a job is asynchronous and already scheduled Asyncio tasks are therefore executed. When the timeout is reached the jobs created by the \"thread\" method jobs cannot be directly killed but rather their ``job.status`` is updated to ``\"CANCELLING\"`` and the user-code is responsible for checking the status of the job and interrupting the execution. This is why the objective value is still present in the results. This behavior is different from the \"process\" method where the jobs are killed directly.\n\nWe can now plot the results of the parallel search. The first plot shows the evolution of the objective.\nThe second plot shows the utilization of the worker over time.\n\nWe can see that the parallel search is able to evaluate a lot more points in the same time budget. This also\nallows the algorithm to explore more of the search space and potentially find better solutions.\nThe utilization plot shows that the workers are used efficiently in the parallel search (above 80%).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(\n        nrows=2,\n        ncols=1,\n        sharex=True,\n        figsize=figure_size(width=600),\n    )\n\nplot_search_trajectory_single_objective_hpo(\n    results[\"parallel\"], mode=\"min\", x_units=\"seconds\", ax=axes[0]\n)\n\nplot_worker_utilization(\n    results[\"parallel\"], num_workers=1, profile_type=\"start/end\", ax=axes[1]\n)\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we compare both search with the execution time is used as the x-axis.\nThe advantage of parallelism is clearly visible by the difference in the number of evaluations and in objective.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=figure_size(width=600))\n\nfor i, (strategy, df) in enumerate(results.items()):\n    plot_search_trajectory_single_objective_hpo(\n        df,\n        show_failures=False,\n        mode=\"min\",\n        x_units=\"seconds\",\n        ax=ax,\n        label=strategy,\n        plot_kwargs={\"color\": f\"C{i}\"},\n        scatter_success_kwargs={\"color\": f\"C{i}\"},\n    )\n\nplt.xlabel(\"Time (sec.)\")\nplt.ylabel(\"Objective\")\nplt.yscale(\"log\")\nplt.grid(visible=True, which=\"minor\", linestyle=\":\")\nplt.grid(visible=True, which=\"major\", linestyle=\"-\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, one could compare to a random search to see if the overheads of the parallel Bayesian optimization are worth it (i.e., the cost of fitting and optimizing the surrogate model).\nThe evaluator is defined similarly to the one used for the parallel Bayesian optimization search:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parallel_evaluator = Evaluator.create(\n    black_box.run_ackley,\n    method=\"thread\",\n    method_kwargs={\n        \"num_workers\": 100, # For the parallel evaluations\n        \"callbacks\": [TqdmCallback()]\n    },\n)\nrandom_search = RandomSearch(problem, parallel_evaluator, random_state=search_kwargs[\"random_state\"])\nresults[\"random\"] = random_search.search(timeout=timeout)\noffset = results[\"random\"][\"m:timestamp_start\"].min()\nresults[\"random\"][\"m:timestamp_start\"] -= offset \nresults[\"random\"][\"m:timestamp_end\"] -= offset \nresults[\"random\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The number of evaluations of the random search is higher than the parallel Bayesian optimization search.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"Number of evaluations for the parallel Bayesian optimization: {len(results['parallel'])}\")\nprint(f\"Number of evaluations for the random search: {len(results['random'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The utilization of the worker is confirmed to be near 100% for the random search.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(\n        nrows=2,\n        ncols=1,\n        sharex=True,\n        figsize=figure_size(width=600),\n    )\n\nplot_search_trajectory_single_objective_hpo(\n    results[\"random\"], mode=\"min\", x_units=\"seconds\", ax=axes[0]\n)\n\nplot_worker_utilization(\n    results[\"random\"], num_workers=1, profile_type=\"start/end\", ax=axes[1]\n)\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, the objective value of the parallel Bayesian optimization search is significantly better than the random search.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = 5\nfig, ax = plt.subplots(figsize=figure_size(width=600))\nlabels = {\n    \"random\": \"Parallel Random Search\",\n    \"sequential\": \"Sequential Bayesian Optimization\",\n    \"parallel\": \"Parallel Bayesian Optimization\",\n    }\nfor i, (key, label) in enumerate(labels.items()):\n    df = results[key]\n    plot_search_trajectory_single_objective_hpo(\n        df,\n        show_failures=False,\n        mode=\"min\",\n        x_units=\"seconds\",\n        ax=ax,\n        label=label,\n        plot_kwargs={\"color\": f\"C{i}\"},\n        scatter_success_kwargs={\"color\": f\"C{i}\", \"alpha\": 0.5},\n    )\n\nplt.xlabel(\"Time (sec.)\")\nplt.ylabel(\"Objective\")\nplt.yscale(\"log\")\nplt.grid(visible=True, which=\"minor\", linestyle=\":\")\nplt.grid(visible=True, which=\"major\", linestyle=\"-\")\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}