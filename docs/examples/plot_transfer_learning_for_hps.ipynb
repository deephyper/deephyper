{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Transfer Learning for Hyperparameter Search\n\n**Author(s)**: Romain Egele.\n\nIn this example we present how to apply transfer-learning for hyperparameter\nsearch. Let's assume you have a bunch of similar tasks for example the search\nof neural networks hyperparameters for different datasets. You can easily\nimagine that close choices of hyperparameters can perform well these\ndifferent datasets even if some light additional tuning can help improve the\nperformance. Therefore, you can perform an expensive search once to then\nreuse the explored set of hyperparameters of thid search and bias the\nfollowing search with it. Here, we will use a cheap to compute and easy to\nunderstand example where we maximise the $f(x) = -\\sum_{i=0}^\n{n-1}$ function. In this case the size of the problem can be defined by the\nvariable $n$. We will start by optimizing the small-size problem\nwhere $n=1$, then apply transfer-learning from to optimize the\nlarger-size problem where $n=2$ and visualize the difference if were\nnot to apply transfer-learning on this larger problem instance.\n\nLet us start by defining the run-functions of the small and large scale problems:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import functools\nimport matplotlib.pyplot as plt\n\nfrom deephyper.hpo import HpProblem\nfrom deephyper.evaluator import Evaluator\nfrom deephyper.evaluator.callback import TqdmCallback\nfrom deephyper.hpo import CBO\n\n\ndef run(config: dict, N: int) -> float:\n    y = -sum([config[f\"x{i}\"] ** 2 for i in range(N)])\n    return y\n\n\nrun_small = functools.partial(run, N=1)\nrun_large = functools.partial(run, N=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we can define the hyperparameter problem space based on $n$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "N = 1\nproblem_small = HpProblem()\nfor i in range(N):\n    problem_small.add_hyperparameter((-10.0, 10.0), f\"x{i}\")\nproblem_small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "N = 2\nproblem_large = HpProblem()\nfor i in range(N):\n    problem_large.add_hyperparameter((-10.0, 10.0), f\"x{i}\")\nproblem_large"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define setup the search and execute it:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = {}\nmax_evals = 20\nevaluator_small = Evaluator.create(\n    run_small, method=\"thread\", method_kwargs={\"callbacks\": [TqdmCallback()]}\n)\nsearch_small = CBO(problem_small, evaluator_small, random_state=42)\nresults[\"Small\"] = search_small.search(max_evals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "evaluator_large = Evaluator.create(\n    run_large, method=\"thread\", method_kwargs={\"callbacks\": [TqdmCallback()]}\n)\nsearch_large = CBO(problem_large, evaluator_large, random_state=42)\nresults[\"Large\"] = search_large.search(max_evals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "evaluator_large_tl = Evaluator.create(\n    run_large, method=\"thread\", method_kwargs={\"callbacks\": [TqdmCallback()]}\n)\nsearch_large_tl = CBO(problem_large, evaluator_large_tl, random_state=42)\nsearch_large_tl.fit_generative_model(results[\"Small\"])\nresults[\"Large+TL\"] = search_large_tl.search(max_evals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we compare the results and quickly see that transfer-learning\nprovided a consequant speed-up for the search:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# from deephyper.analysis import figure_size\nfrom deephyper.analysis.hpo import plot_search_trajectory_single_objective_hpo\n\nfig, ax = plt.subplots()\n\nfor strategy, df in results.items():\n    # x = [i for i in range(len(df))]\n    # plt.scatter(x, df.objective, label=strategy, alpha=0.5)\n    # plt.plot(x, df.objective.cummax(), alpha=0.5)\n    plot_search_trajectory_single_objective_hpo(\n        df, show_failures=False, ax=ax, label=strategy\n    )\n\n\nplt.xlabel(\"Time (sec.)\")\nplt.ylabel(\"Objective\")\nplt.grid()\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}