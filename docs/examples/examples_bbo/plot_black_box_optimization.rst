
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/examples_bbo/plot_black_box_optimization.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_examples_examples_bbo_plot_black_box_optimization.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_examples_bbo_plot_black_box_optimization.py:


An Introduction to Black-Box Optimization with DeepHyper
--------------------------------------------------------

In this tutorial, we introduce you to the notion of [black-box optimization](https://en.wikipedia.org/wiki/Derivative-free_optimization) (a.k.a., derivative-free optimization) with DeepHyper.

Black-box optimization is a field of optimization research where an objective function :math:`f(x) = y \in \mathbb{R}$` is optimized only based on input-output observations :math:`\{ (x_1,y_1), \ldots, (x_n, y_n) \}_i`.
 
Let's start by installing DeepHyper!

.. GENERATED FROM PYTHON SOURCE LINES 11-22

.. dropdown:: Code (Import statements)

    .. code-block:: Python


        #   %%bash
        #   pip install deephyper

        try:
            import deephyper
            print(deephyper.__version__)
        except (ImportError, ModuleNotFoundError):
            pass





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    0.9.2




.. GENERATED FROM PYTHON SOURCE LINES 23-36

Optimization Problem
--------------------

The optimization problem is based  on two components:

1. The black-box function that we want to optimize.
2. The search space or domain of input variables over which we want to optimize.

Black-Box Function
------------------

DeepHyper is developed to optimize black-box functions.
Here, we define the function :math:`f(x) = - x ^ 2` that we want to maximise (the maximum being :math:`f(x=0) = 0` on :math:`I_x = [-10;10]`). The black-box function `f` takes as input a `config` dictionary from which we retrieve the variables of interest.

.. GENERATED FROM PYTHON SOURCE LINES 38-41

.. code-block:: Python

    def f(job):
        return -job.parameters["x"] ** 2








.. GENERATED FROM PYTHON SOURCE LINES 42-46

Search Space of Input Variables
-------------------------------

In this example, we have only one variable $x$ for the black-box functin $f$. We empirically decide to optimize this variable $x$ on the interval :math:`I_x = [-10;10]`. To do so we use the `HpProblem` from DeepHyper and add a **real** hyperparameter by using a `tuple` of two `floats`.

.. GENERATED FROM PYTHON SOURCE LINES 48-57

.. code-block:: Python

    from deephyper.hpo import HpProblem

    problem = HpProblem()

    # Define the variable you want to optimize
    problem.add_hyperparameter((-10.0, 10.0), "x")

    problem





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Configuration space object:
      Hyperparameters:
        x, Type: UniformFloat, Range: [-10.0, 10.0], Default: 0.0




.. GENERATED FROM PYTHON SOURCE LINES 58-63

Evaluator Interface
-------------------

DeepHyper uses an API called `Evaluator` to distribute the computation of black-box functions and adapt to different backends (e.g., threads, processes, MPI, Ray). An `Evaluator` object wraps the black-box function `f` that we want to optimize. Then a `method` parameter is used to select the backend and `method_kwargs` defines some available options of this backend.


.. GENERATED FROM PYTHON SOURCE LINES 63-67

.. code-block:: Python

   
    # .. hint::
    #    | The `method="thread"` provides parallel computation only if the black-box is releasing the global interpretor lock (GIL). Therefore, if you want parallelism in Jupyter notebooks you should use the Ray evaluator (`method="ray"`) after installing Ray with `pip install ray`.








.. GENERATED FROM PYTHON SOURCE LINES 68-69

It is possible to define callbacks to extend the behaviour of `Evaluator` each time a function-evaluation is launched or completed. In this example we use the `TqdmCallback` to follow the completed evaluations and the evolution of the objective with a progress-bar.

.. GENERATED FROM PYTHON SOURCE LINES 69-87

.. dropdown:: Code (Code)

    .. code-block:: Python


        from deephyper.evaluator import Evaluator
        from deephyper.evaluator.callback import TqdmCallback


        # define the evaluator to distribute the computation
        evaluator = Evaluator.create(
            f,
            method="thread",
            method_kwargs={
                "num_workers": 4,
                "callbacks": [TqdmCallback()]
            },
        )

        print(f"Evaluator has {evaluator.num_workers} available worker{'' if evaluator.num_workers == 1 else 's'}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Evaluator has 4 available workers




.. GENERATED FROM PYTHON SOURCE LINES 88-92

Search Algorithm
----------------

The next step is to define the search algorithm that we want to use. Here, we choose `CBO` (Centralized Bayesian Optimization) which is a sampling based Bayesian optimization strategy. This algorithm has the advantage of being asynchronous thanks to a constant liar strategy which is crutial to keep a good utilization of the resources when the number of available workers increases.

.. GENERATED FROM PYTHON SOURCE LINES 92-105

.. dropdown:: Code (Code)

    .. code-block:: Python


        from deephyper.hpo import CBO

        # define your search
        search = CBO(
            problem,
            evaluator,
            acq_func="UCB",  # Acquisition function to Upper Confidence Bound
            multi_point_strategy="qUCB",  # Fast Multi-point strategy with q-Upper Confidence Bound
            n_jobs=2,  # Number of threads to fit surrogate models in parallel
        )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    WARNING:root:Results file already exists, it will be renamed to /Users/35e/Projects/DeepHyper/deephyper/examples/examples_bbo/results_20250228-103140.csv




.. GENERATED FROM PYTHON SOURCE LINES 106-107

Then, we can execute the search for a given number of iterations by using the `search.search(max_evals=...)`. It is also possible to use the `timeout` parameter if one needs a specific time budget (e.g., restricted computational time in machine learning competitions, allocation time in HPC).

.. GENERATED FROM PYTHON SOURCE LINES 109-111

.. code-block:: Python

    results = search.search(max_evals=100)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/100 [00:00<?, ?it/s]      1%|          | 1/100 [00:00<00:00, 13357.66it/s, failures=0, objective=-67.9]      2%|▏         | 2/100 [00:00<00:00, 6388.89it/s, failures=0, objective=-67.5]       3%|▎         | 3/100 [00:00<00:00, 5904.70it/s, failures=0, objective=-31.8]      4%|▍         | 4/100 [00:00<00:00, 5747.59it/s, failures=0, objective=-31.8]      5%|▌         | 5/100 [00:00<00:00, 145.19it/s, failures=0, objective=-31.8]       6%|▌         | 6/100 [00:00<00:00, 173.05it/s, failures=0, objective=-12.1]      7%|▋         | 7/100 [00:00<00:00, 200.84it/s, failures=0, objective=-12.1]      8%|▊         | 8/100 [00:00<00:00, 228.30it/s, failures=0, objective=-0.0379]      9%|▉         | 9/100 [00:00<00:00, 159.10it/s, failures=0, objective=-0.0379]     10%|█         | 10/100 [00:00<00:00, 176.04it/s, failures=0, objective=-0.0379]     11%|█         | 11/100 [00:00<00:00, 193.07it/s, failures=0, objective=-0.0379]     12%|█▏        | 12/100 [00:00<00:00, 210.01it/s, failures=0, objective=-0.0379]     13%|█▎        | 13/100 [00:00<00:02, 30.84it/s, failures=0, objective=-0.0379]      13%|█▎        | 13/100 [00:00<00:02, 30.84it/s, failures=0, objective=-0.0379]     14%|█▍        | 14/100 [00:00<00:02, 30.84it/s, failures=0, objective=-0.0379]     15%|█▌        | 15/100 [00:00<00:02, 30.84it/s, failures=0, objective=-0.0379]     16%|█▌        | 16/100 [00:00<00:02, 30.84it/s, failures=0, objective=-0.0379]     17%|█▋        | 17/100 [00:00<00:03, 21.67it/s, failures=0, objective=-0.0379]     17%|█▋        | 17/100 [00:00<00:03, 21.67it/s, failures=0, objective=-0.0379]     18%|█▊        | 18/100 [00:00<00:03, 21.67it/s, failures=0, objective=-0.0379]     19%|█▉        | 19/100 [00:00<00:03, 21.67it/s, failures=0, objective=-0.0379]     20%|██        | 20/100 [00:00<00:03, 21.67it/s, failures=0, objective=-0.000458]     21%|██        | 21/100 [00:01<00:04, 17.22it/s, failures=0, objective=-0.000458]     21%|██        | 21/100 [00:01<00:04, 17.22it/s, failures=0, objective=-0.000458]     22%|██▏       | 22/100 [00:01<00:04, 17.22it/s, failures=0, objective=-0.000458]     23%|██▎       | 23/100 [00:01<00:04, 17.22it/s, failures=0, objective=-0.000292]     24%|██▍       | 24/100 [00:01<00:04, 17.22it/s, failures=0, objective=-0.000292]     25%|██▌       | 25/100 [00:01<00:04, 16.55it/s, failures=0, objective=-0.000292]     25%|██▌       | 25/100 [00:01<00:04, 16.55it/s, failures=0, objective=-9.34e-5]      26%|██▌       | 26/100 [00:01<00:04, 16.55it/s, failures=0, objective=-9.34e-5]     27%|██▋       | 27/100 [00:01<00:04, 16.55it/s, failures=0, objective=-9.34e-5]     28%|██▊       | 28/100 [00:01<00:04, 16.55it/s, failures=0, objective=-9.34e-5]     29%|██▉       | 29/100 [00:01<00:04, 16.14it/s, failures=0, objective=-9.34e-5]     29%|██▉       | 29/100 [00:01<00:04, 16.14it/s, failures=0, objective=-9.34e-5]     30%|███       | 30/100 [00:01<00:04, 16.14it/s, failures=0, objective=-9.34e-5]     31%|███       | 31/100 [00:01<00:04, 16.14it/s, failures=0, objective=-9.34e-5]     32%|███▏      | 32/100 [00:01<00:04, 16.14it/s, failures=0, objective=-9.34e-5]     33%|███▎      | 33/100 [00:01<00:04, 14.28it/s, failures=0, objective=-9.34e-5]     33%|███▎      | 33/100 [00:01<00:04, 14.28it/s, failures=0, objective=-9.34e-5]     34%|███▍      | 34/100 [00:01<00:04, 14.28it/s, failures=0, objective=-9.34e-5]     35%|███▌      | 35/100 [00:01<00:04, 14.28it/s, failures=0, objective=-9.34e-5]     36%|███▌      | 36/100 [00:01<00:04, 14.28it/s, failures=0, objective=-9.34e-5]     37%|███▋      | 37/100 [00:02<00:04, 14.96it/s, failures=0, objective=-9.34e-5]     37%|███▋      | 37/100 [00:02<00:04, 14.96it/s, failures=0, objective=-2.78e-5]     38%|███▊      | 38/100 [00:02<00:04, 14.96it/s, failures=0, objective=-4.65e-7]     39%|███▉      | 39/100 [00:02<00:04, 14.96it/s, failures=0, objective=-4.65e-7]     40%|████      | 40/100 [00:02<00:04, 14.96it/s, failures=0, objective=-4.65e-7]     41%|████      | 41/100 [00:02<00:04, 13.86it/s, failures=0, objective=-4.65e-7]     41%|████      | 41/100 [00:02<00:04, 13.86it/s, failures=0, objective=-4.65e-7]     42%|████▏     | 42/100 [00:02<00:04, 13.86it/s, failures=0, objective=-4.65e-7]     43%|████▎     | 43/100 [00:02<00:04, 13.86it/s, failures=0, objective=-4.65e-7]     44%|████▍     | 44/100 [00:02<00:04, 13.86it/s, failures=0, objective=-4.65e-7]     45%|████▌     | 45/100 [00:02<00:03, 14.16it/s, failures=0, objective=-4.65e-7]     45%|████▌     | 45/100 [00:02<00:03, 14.16it/s, failures=0, objective=-4.65e-7]     46%|████▌     | 46/100 [00:02<00:03, 14.16it/s, failures=0, objective=-4.65e-7]     47%|████▋     | 47/100 [00:02<00:03, 14.16it/s, failures=0, objective=-4.65e-7]     48%|████▊     | 48/100 [00:02<00:03, 14.16it/s, failures=0, objective=-4.65e-7]     49%|████▉     | 49/100 [00:03<00:03, 13.20it/s, failures=0, objective=-4.65e-7]     49%|████▉     | 49/100 [00:03<00:03, 13.20it/s, failures=0, objective=-1.33e-8]     50%|█████     | 50/100 [00:03<00:03, 13.20it/s, failures=0, objective=-1.33e-8]     51%|█████     | 51/100 [00:03<00:03, 13.20it/s, failures=0, objective=-1.33e-8]     52%|█████▏    | 52/100 [00:03<00:03, 13.20it/s, failures=0, objective=-1.33e-8]     53%|█████▎    | 53/100 [00:03<00:03, 13.71it/s, failures=0, objective=-1.33e-8]     53%|█████▎    | 53/100 [00:03<00:03, 13.71it/s, failures=0, objective=-1.33e-8]     54%|█████▍    | 54/100 [00:03<00:03, 13.71it/s, failures=0, objective=-1.33e-8]     55%|█████▌    | 55/100 [00:03<00:03, 13.71it/s, failures=0, objective=-1.33e-8]     56%|█████▌    | 56/100 [00:03<00:03, 13.71it/s, failures=0, objective=-1.33e-8]     57%|█████▋    | 57/100 [00:03<00:03, 14.09it/s, failures=0, objective=-1.33e-8]     57%|█████▋    | 57/100 [00:03<00:03, 14.09it/s, failures=0, objective=-1.33e-8]     58%|█████▊    | 58/100 [00:03<00:02, 14.09it/s, failures=0, objective=-1.33e-8]     59%|█████▉    | 59/100 [00:03<00:02, 14.09it/s, failures=0, objective=-1.33e-8]     60%|██████    | 60/100 [00:03<00:02, 14.09it/s, failures=0, objective=-1.33e-8]     61%|██████    | 61/100 [00:04<00:02, 13.04it/s, failures=0, objective=-1.33e-8]     61%|██████    | 61/100 [00:04<00:02, 13.04it/s, failures=0, objective=-1.33e-8]     62%|██████▏   | 62/100 [00:04<00:02, 13.04it/s, failures=0, objective=-1.33e-8]     63%|██████▎   | 63/100 [00:04<00:02, 13.04it/s, failures=0, objective=-1.33e-8]     64%|██████▍   | 64/100 [00:04<00:02, 13.04it/s, failures=0, objective=-1.33e-8]     65%|██████▌   | 65/100 [00:04<00:02, 13.70it/s, failures=0, objective=-1.33e-8]     65%|██████▌   | 65/100 [00:04<00:02, 13.70it/s, failures=0, objective=-1.33e-8]     66%|██████▌   | 66/100 [00:04<00:02, 13.70it/s, failures=0, objective=-1.33e-8]     67%|██████▋   | 67/100 [00:04<00:02, 13.70it/s, failures=0, objective=-1.33e-8]     68%|██████▊   | 68/100 [00:04<00:02, 13.70it/s, failures=0, objective=-1.33e-8]     69%|██████▉   | 69/100 [00:04<00:02, 12.82it/s, failures=0, objective=-1.33e-8]     69%|██████▉   | 69/100 [00:04<00:02, 12.82it/s, failures=0, objective=-1.33e-8]     70%|███████   | 70/100 [00:04<00:02, 12.82it/s, failures=0, objective=-1.33e-8]     71%|███████   | 71/100 [00:04<00:02, 12.82it/s, failures=0, objective=-1.33e-8]     72%|███████▏  | 72/100 [00:04<00:02, 12.82it/s, failures=0, objective=-1.33e-8]     73%|███████▎  | 73/100 [00:04<00:02, 13.33it/s, failures=0, objective=-1.33e-8]     73%|███████▎  | 73/100 [00:04<00:02, 13.33it/s, failures=0, objective=-1.33e-8]     74%|███████▍  | 74/100 [00:04<00:01, 13.33it/s, failures=0, objective=-1.33e-8]     75%|███████▌  | 75/100 [00:04<00:01, 13.33it/s, failures=0, objective=-1.33e-8]     76%|███████▌  | 76/100 [00:04<00:01, 13.33it/s, failures=0, objective=-1.33e-8]     77%|███████▋  | 77/100 [00:05<00:01, 12.68it/s, failures=0, objective=-1.33e-8]     77%|███████▋  | 77/100 [00:05<00:01, 12.68it/s, failures=0, objective=-1.33e-8]     78%|███████▊  | 78/100 [00:05<00:01, 12.68it/s, failures=0, objective=-1.33e-8]     79%|███████▉  | 79/100 [00:05<00:01, 12.68it/s, failures=0, objective=-1.33e-8]     80%|████████  | 80/100 [00:05<00:01, 12.68it/s, failures=0, objective=-1.33e-8]     81%|████████  | 81/100 [00:05<00:01, 13.62it/s, failures=0, objective=-1.33e-8]     81%|████████  | 81/100 [00:05<00:01, 13.62it/s, failures=0, objective=-3e-9]        82%|████████▏ | 82/100 [00:05<00:01, 13.62it/s, failures=0, objective=-3e-9]     83%|████████▎ | 83/100 [00:05<00:01, 13.62it/s, failures=0, objective=-3e-9]     84%|████████▍ | 84/100 [00:05<00:01, 13.62it/s, failures=0, objective=-3e-9]     85%|████████▌ | 85/100 [00:05<00:01, 14.02it/s, failures=0, objective=-3e-9]     85%|████████▌ | 85/100 [00:05<00:01, 14.02it/s, failures=0, objective=-3e-9]     86%|████████▌ | 86/100 [00:05<00:00, 14.02it/s, failures=0, objective=-3e-9]     87%|████████▋ | 87/100 [00:05<00:00, 14.02it/s, failures=0, objective=-3e-9]     88%|████████▊ | 88/100 [00:05<00:00, 14.02it/s, failures=0, objective=-3e-9]     89%|████████▉ | 89/100 [00:06<00:00, 12.95it/s, failures=0, objective=-3e-9]     89%|████████▉ | 89/100 [00:06<00:00, 12.95it/s, failures=0, objective=-3e-9]     90%|█████████ | 90/100 [00:06<00:00, 12.95it/s, failures=0, objective=-3e-9]     91%|█████████ | 91/100 [00:06<00:00, 12.95it/s, failures=0, objective=-3e-9]     92%|█████████▏| 92/100 [00:06<00:00, 12.95it/s, failures=0, objective=-3e-9]     93%|█████████▎| 93/100 [00:06<00:00, 13.75it/s, failures=0, objective=-3e-9]     93%|█████████▎| 93/100 [00:06<00:00, 13.75it/s, failures=0, objective=-3e-9]     94%|█████████▍| 94/100 [00:06<00:00, 13.75it/s, failures=0, objective=-3e-9]     95%|█████████▌| 95/100 [00:06<00:00, 13.75it/s, failures=0, objective=-3e-9]     96%|█████████▌| 96/100 [00:06<00:00, 13.75it/s, failures=0, objective=-3e-9]     97%|█████████▋| 97/100 [00:06<00:00, 13.09it/s, failures=0, objective=-3e-9]     97%|█████████▋| 97/100 [00:06<00:00, 13.09it/s, failures=0, objective=-3e-9]     98%|█████████▊| 98/100 [00:06<00:00, 13.09it/s, failures=0, objective=-3e-9]     99%|█████████▉| 99/100 [00:06<00:00, 13.09it/s, failures=0, objective=-3e-9]    100%|██████████| 100/100 [00:06<00:00, 13.09it/s, failures=0, objective=-3e-9]



.. GENERATED FROM PYTHON SOURCE LINES 112-119

Finally, let us visualize the results. The `search(...)` returns a DataFrame also saved locally under `results.csv` (in case of crash we don't want to lose the possibly expensive evaluations already performed).

The DataFrame contains as columns:
1. the optimized hyperparameters: such as :math:`x` in our case.
2. the `objective` **maximised** which directly match the results of the :math:`f` function in our example.
3. the `job_id` of each evaluated function (increased incrementally following the order of created evaluations).
4. the time of creation/collection of each task `timestamp_submit` and `timestamp_gather` respectively (in secondes, since the creation of the Evaluator).

.. GENERATED FROM PYTHON SOURCE LINES 121-123

.. code-block:: Python

    results






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>p:x</th>
          <th>objective</th>
          <th>job_id</th>
          <th>job_status</th>
          <th>m:timestamp_submit</th>
          <th>m:timestamp_gather</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>-8.242020</td>
          <td>-6.793090e+01</td>
          <td>1</td>
          <td>DONE</td>
          <td>0.058465</td>
          <td>0.059750</td>
        </tr>
        <tr>
          <th>1</th>
          <td>-8.216299</td>
          <td>-6.750756e+01</td>
          <td>3</td>
          <td>DONE</td>
          <td>0.058497</td>
          <td>0.060829</td>
        </tr>
        <tr>
          <th>2</th>
          <td>5.638380</td>
          <td>-3.179133e+01</td>
          <td>0</td>
          <td>DONE</td>
          <td>0.058405</td>
          <td>0.061030</td>
        </tr>
        <tr>
          <th>3</th>
          <td>7.545360</td>
          <td>-5.693246e+01</td>
          <td>2</td>
          <td>DONE</td>
          <td>0.058482</td>
          <td>0.061217</td>
        </tr>
        <tr>
          <th>4</th>
          <td>9.401603</td>
          <td>-8.839015e+01</td>
          <td>4</td>
          <td>DONE</td>
          <td>0.093974</td>
          <td>0.094943</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>95</th>
          <td>-0.000228</td>
          <td>-5.213887e-08</td>
          <td>94</td>
          <td>DONE</td>
          <td>6.460006</td>
          <td>6.462036</td>
        </tr>
        <tr>
          <th>96</th>
          <td>0.000477</td>
          <td>-2.273183e-07</td>
          <td>97</td>
          <td>DONE</td>
          <td>6.800546</td>
          <td>6.801243</td>
        </tr>
        <tr>
          <th>97</th>
          <td>0.000713</td>
          <td>-5.085943e-07</td>
          <td>96</td>
          <td>DONE</td>
          <td>6.800515</td>
          <td>6.801720</td>
        </tr>
        <tr>
          <th>98</th>
          <td>0.000477</td>
          <td>-2.273183e-07</td>
          <td>98</td>
          <td>DONE</td>
          <td>6.800561</td>
          <td>6.801949</td>
        </tr>
        <tr>
          <th>99</th>
          <td>0.000477</td>
          <td>-2.273183e-07</td>
          <td>99</td>
          <td>DONE</td>
          <td>6.800575</td>
          <td>6.802172</td>
        </tr>
      </tbody>
    </table>
    <p>100 rows × 6 columns</p>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 124-125

We can also plot the evolution of the objective to verify that we converge correctly toward :math:`0`.

.. GENERATED FROM PYTHON SOURCE LINES 125-137

.. dropdown:: Code (Code)

    .. code-block:: Python


        import matplotlib.pyplot as plt
        from deephyper.analysis.hpo import plot_search_trajectory_single_objective_hpo

        fig, ax = plot_search_trajectory_single_objective_hpo(results, mode="min")
        plt.title("Search Trajectory")
        plt.yscale("log")
        plt.show()






.. image-sg:: /examples/examples_bbo/images/sphx_glr_plot_black_box_optimization_001.png
   :alt: Search Trajectory
   :srcset: /examples/examples_bbo/images/sphx_glr_plot_black_box_optimization_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /Users/35e/Projects/DeepHyper/deephyper/examples/examples_bbo/plot_black_box_optimization.py:133: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
      plt.show()





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 9.663 seconds)


.. _sphx_glr_download_examples_examples_bbo_plot_black_box_optimization.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_black_box_optimization.ipynb <plot_black_box_optimization.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_black_box_optimization.py <plot_black_box_optimization.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_black_box_optimization.zip <plot_black_box_optimization.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
