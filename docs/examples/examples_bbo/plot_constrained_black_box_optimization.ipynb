{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Constrained Black-Box Optimization with Rejection Sampling\n\n**Author(s)**: Romain Egele.\n\nIn this tutorial, we illustrate how to solve constrained [black-box optimization (Wikipedia)](https://en.wikipedia.org/wiki/Derivative-free_optimization) (also known as derivative-free optimization) using DeepHyper.\n\nBlack-box optimization refers to a class of methods where an objective function $f(x) = y \\in \\mathbb{R}$ can only be queried through input\u2013output evaluations $\\{ (x_1, y_1), \\ldots, (x_n, y_n) \\}$. No closed-form expression, derivatives, or structural information about $f$ are required.\n\nIn *constrained* optimization, we further introduce one or more rules that restrict the set of admissible solutions. These constraints carve out the feasible region of the search space and can substantially influence both the behavior and performance of the optimizer.\n\nIn the following example, we define a simple two-dimensional problem, impose a linear constraint, and solve it using DeepHyper\u2019s Centralized Bayesian Optimization (CBO) engine.\n\nThere exists multiple ways of handling constraints in DeepHyper:\n\n#. Rejection sampling (shown in this tutorial) where we sample from the unconstrained search space \n   then reject unfeasible solutions. While this approach is simple it can become computationnaly \n   intractable.\n#. Learning to avoid failures (see `Learn to Avoid Failures with Bayesian Optimization <sphx_glr_examples_examples_bbo_plot_notify_failures_hpo.py>`).\n#. Define the constraint as an other objective in a multi-objective optimization setup (tutorial coming soon).\n#. Custom chained sampler (tutorial coming soon).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom deephyper.analysis.hpo import plot_search_trajectory_single_objective_hpo, parameters_at_max\nfrom deephyper.hpo import HpProblem, CBO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimization Problem\nWe define a 2D search space over variables ``x`` and ``y``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pb = HpProblem()\npb.add((-10.0, 10.0), \"x\")\npb.add((-10.0, 10.0), \"y\")\n\n\ndef f(job):\n    \"\"\"Objective function: maximize x^2 + y^2.\"\"\"\n    return job.parameters[\"x\"] ** 2 + job.parameters[\"y\"] ** 2\n\n\ndef constraint_fn_test(s: pd.DataFrame):\n    \"\"\"Feasibility condition: |x| + |y| <= 10.\"\"\"\n    return np.abs(s[\"x\"]) + np.abs(s[\"y\"]) <= 10\n\n\npb.set_constraint_fn(constraint_fn_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now set up a constrained Bayesian optimization search using a genetic algorithm\nto optimize the acquisition function periodically.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search = CBO(\n    pb,\n    acq_optimizer=\"ga\",\n    acq_optimizer_kwargs={\"acq_optimizer_freq\": 2},\n    acq_func_kwargs={\n        # Exploration/Exploitation mechanism\n        \"kappa\": 200.0,\n        \"scheduler\": {\"type\": \"periodic-exp-decay\", \"period\": 20, \"kappa_final\": 1.96},\n    },\n    verbose=1,\n)\nresults = search.search(f, max_evals=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extracting the Best Parameters\nTo recover the parameters corresponding to the best observed objective value,\nwe can use :func:`deephyper.analysis.hpo.parameters_at_max`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parameters, objective = parameters_at_max(results)\nprint(\"\\nOptimum values\")\nprint(f\"x: {parameters['x']:.3f}, y: {parameters['y']:.2f}\")\nprint(\"objective:\", objective)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the Search Trajectory\nWe plot the evolution of the best objective value to verify that optimization\nprogresses correctly toward the maximum $100$.\n\nWe clearly see the periodic exploration/exploitation effect of the scheduler.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "WIDTH_PLOTS = 8\nHEIGHT_PLOTS = WIDTH_PLOTS / 1.618\n\nfig, ax = plt.subplots(figsize=(WIDTH_PLOTS, HEIGHT_PLOTS))\nplot_search_trajectory_single_objective_hpo(results, mode=\"max\", ax=ax)\n_ = plt.title(\"Search Trajectory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the Feasible Region and Evaluations\nWe now plot all evaluated points in the (x, y) plane, color-coded by\nobjective value, along with the constraint boundary ``x + y = 10``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(WIDTH_PLOTS, HEIGHT_PLOTS))\nitem = ax.scatter(results[\"p:x\"], results[\"p:y\"], c=results[\"objective\"], label=\"Evaluations\")\nax.plot([0, 10], [10, 0], \"r:\")\nax.plot([0, 10], [-10, 0], \"r:\")\nax.plot([-10, 0], [0, -10], \"r:\")\nax.plot([0, -10], [10, 0], \"r:\", label=\"Constraint\")\nax.set_xlabel(r\"$x$\")\nax.set_ylabel(r\"$y$\")\nax.set_xlim(-10, 10)\nax.set_ylim(-10, 10)\nax.legend()\nax.grid()\nax.grid(which=\"minor\", linestyle=\":\")\ncb = plt.colorbar(item)\ncb.set_label(r\"Objective\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}