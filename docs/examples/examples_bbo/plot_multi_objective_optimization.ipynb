{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Mutli-Objective Black-Box Optimization\n\nIn this tutorial, we will explore how to run black-box multi-objective optimization (MOO). In this setting, the goal is to resolve the following problem:\n\n\\begin{align}\\text{max}_x (f_0(x), f_1(x), ..., f_n(x))\\end{align}\n\nwhere $x$ is the set of optimized variables and $f_i$ are the different objectives. In DeepHyper, we use scalarization to transform such multi-objective problem into a single-objective problem:\n\n\\begin{align}\\text{max}_x s_w((f_0(x), f_1(x), ..., f_n(x)))\\end{align}\n\nwhere $w$ is a set of weights which manages the trade-off between objectives and $s_w : \\mathbb{R}^n \\rightarrow \\mathbb{R}$. The weight vector $w$ is randomized and re-sampled for each new batch of suggestion from the optimizer.\n\nWe will look at the DTLZ benchmark suite, a classic in multi-objective optimization (MOO) litterature. This benchmark exibit some characteristic cases of MOO. By default, this tutorial is loading the DTLZ-II benchmark which exibit a Pareto-Front with a concave shape.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation and imports\n\nInstalling dependencies with the `pip installation <install-pip>` is recommended. It requires **Python >= 3.10**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%bash\npip install deephyper\npip install -e \"git+https://github.com/deephyper/benchmark.git@main#egg=deephyper-benchmark\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Import statements\nimport matplotlib.pyplot as plt\n\nfrom deephyper.hpo import CBO\nfrom deephyper_benchmark.benchmarks.dtlz import DTLZBenchmark\n\nWIDTH_PLOTS = 8\nHEIGHT_PLOTS = WIDTH_PLOTS / 1.618\n\nn_objectives = 2\nbench = DTLZBenchmark(nobj=n_objectives)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can display the variable search space of the benchmark we just loaded:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bench.problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To define a black-box for multi-objective optimization it is very similar to single-objective optimization at the difference that the ``objective`` can now be a list of values. A first possibility is:\n\n```python\ndef run(job):\n    ...\n    return objective_0, objective_1, ..., objective_n\n```\nwhich just returns the objectives to optimize as a tuple. If additionnal metadata are interesting to gather for each evaluation it is also possible to return them by following this format:\n\n```python\ndef run(job):\n    ...\n    return {\n        \"objective\": [objective_0, objective_1, ..., objective_n],\n        \"metadata\": {\n            \"flops\": ...,\n            \"memory_footprint\": ...,\n            \"duration\": ...,\n         }\n     }\n```\neach of the metadata needs to be JSON serializable and will be returned in the final results with a column name formatted as ``m:metadata_key`` such as ``m:duration``.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the search algorithm, we use the centralized Bayesian Optimization search (CBO).\nSearch algorithm\n\nThe arguments specific to multi-objective optimization are:\n\n- ``moo_scalarization_strategy`` is used to specify the scalarization strategy. \n  Chebyshev  scalarizationis capable of generating a diverse set of solutions for non-convex problems.\n- ``moo_scalarization_weight`` argument is used to specify the weight of objectives in the scalarization.\n  ``\"random\"`` is used to generate a random weight vector at each iteration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search = CBO(\n    bench.problem,\n    bench.run_function,\n    acq_optimizer=\"sampling\",\n    moo_scalarization_strategy=\"AugChebyshev\",\n    moo_scalarization_weight=\"random\",\n    verbose=1,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Launch the search for a given number of evaluations\nother stopping criteria can be used (e.g. timeout, early-stopping/convergence)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = search.search(max_evals=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A Pandas table of results is returned by the search and also saved at ``./results.csv``. An other location can be specified by using ``CBO(..., log_dir=...)``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this table we retrieve:\n\n- columns starting by ``p:`` which are the optimized variables.\n- the ``objective_{i}`` are the objectives returned by the black-box function.\n- the ``job_id`` is the identifier of the executed evaluations.\n- columns starting by ``m:`` are metadata returned by the black-box function.\n- ``pareto_efficient`` is a column only returned for MOO which specify if the evaluation is part of the set of optimal solutions.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us use this table to visualize evaluated objectives.\nThe estimated optimal solutions will be colored in red.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Plot evaluated objectives\nfig, ax = plt.subplots(figsize=(WIDTH_PLOTS, HEIGHT_PLOTS), tight_layout=True)\n_ = ax.plot(\n    -results[~results[\"pareto_efficient\"]][\"objective_0\"],\n    -results[~results[\"pareto_efficient\"]][\"objective_1\"],\n    \"o\",\n    color=\"blue\",\n    alpha=0.7,\n    label=\"Non Pareto-Efficient\",\n)\n_ = ax.plot(\n    -results[results[\"pareto_efficient\"]][\"objective_0\"],\n    -results[results[\"pareto_efficient\"]][\"objective_1\"],\n    \"o\",\n    color=\"red\",\n    alpha=0.7,\n    label=\"Pareto-Efficient\",\n)\n_ = ax.grid()\n_ = ax.legend()\n_ = ax.set_xlabel(\"Objective 0\")\n_ = ax.set_ylabel(\"Objective 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us look the evolution of the hypervolume indicator.\nThis metric should increase over time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Plot hypervolume\nscorer = bench.scorer\nhvi = scorer.hypervolume(results[[\"objective_0\", \"objective_1\"]].values)\nx = list(range(1, len(hvi)+1))\nfig, ax = plt.subplots(figsize=(WIDTH_PLOTS, HEIGHT_PLOTS), tight_layout=True)\n_ = ax.plot(x, hvi)\n_ = ax.grid()\n_ = ax.set_xlabel(\"Evaluations\")\n_ = ax.set_ylabel(\"Hypervolume Indicator\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}