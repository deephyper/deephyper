{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Generating Parameters with Experimental Design\n\n**Author(s)**: Romain Egele.\n\nThis example demonstrates how to evaluate parameters following a standard experimental\ndesign such as random design, factorial design (a.k.a., grid search) and quasi-monte-carlo\ndesigns (e.g., lhs, sobol).\n\nMore specifically in this example we will show factorial design.\n\nSee [Design of experiments (Wikipedia)](https://en.wikipedia.org/wiki/Design_of_experiments) to learn more about this topic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Import statements\nimport os\nimport shutil\n\nimport matplotlib.pyplot as plt\n\nfrom deephyper.analysis._matplotlib import update_matplotlib_rc\nfrom deephyper.hpo import HpProblem\nfrom deephyper.hpo import ExperimentalDesignSearch\n\n\nupdate_matplotlib_rc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by defining the search space of parameters. \nFor the purpose of demonstration, we will define three variables of different \"types\":\n\n- `x`: is a real parameter drawn from a Log Uniform distribution in order to uniformly draw small and large values from the defined range of values. Otherwise we would have low probability of testing values near the lower-bound.\n- `y`: is a discrete parameter drawn from a Uniform distribution. The discrete type is infered from the Python type of the bounds `int`.\n- `z`: is a categorical ordinal parameter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "problem = HpProblem()\nproblem.add_hyperparameter((0.0001, 100.0, \"log-uniform\"), \"x\")\nproblem.add_hyperparameter((0, 100), \"y\")\nproblem.add_hyperparameter([1, 2, 3], \"z\")\nproblem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the black-box function that we want to evaluate with these parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def run(job):\n    objective = job.parameters[\"x\"] + job.parameters[\"y\"] + job.parameters[\"z\"]\n    return objective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Clean up legacy results\nlog_dir = \"eds_logs\"\nif os.path.exists(log_dir):\n    shutil.rmtree(log_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define the search that will generate parameters. For standard experimental designs we use\nthe :class:`deephyper.hpo.ExperimentalDesignSearch` class. For a grid search, we set ``design=\"grid\"``. \nIt is good to note that the :class:`deephyper.evaluator.Evaluator` can also be used with this class to parallelize evaluations.\nAlso, it is important to set `n_points` and `max_evals` to the same value.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "max_evals = 200\nsearch = ExperimentalDesignSearch(\n    problem, \n    run, \n    n_points=max_evals, \n    design=\"grid\", \n    log_dir=log_dir,\n)\nresults = search.search(max_evals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we plot the results from the collected DataFrame.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. dropdown:: Make plot\nfig, ax = plt.subplots()\nax.scatter(results[\"p:x\"], results[\"p:y\"], c=results[\"p:z\"], alpha=0.3)\nax.set_xscale(\"log\")\n_ = plt.xlabel(\"x\")\n_ = plt.ylabel(\"y\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}