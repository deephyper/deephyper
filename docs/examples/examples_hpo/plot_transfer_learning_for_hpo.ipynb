{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Applying Transfer Learning to Hyperparameter Optimization\n\n**Author(s)**: Romain Egele.\n\nIn this example, we demonstrate how to leverage transfer learning for hyperparameter optimization. Imagine you are working on multiple related tasks, such as optimizing the hyperparameters of neural networks for various datasets. It's reasonable to expect that similar hyperparameter configurations might perform well across these datasets, even if some minor adjustments are needed to fine-tune performance.\n\nBy conducting a thorough (and potentially expensive) search on one task, you can reuse the resulting hyperparameter set to guide and accelerate optimization for subsequent tasks. This approach reduces computational costs while maintaining high performance.\n\nTo illustrate, we will use a simple and computationally inexpensive example: minimizing the function $f(x) = \\sum_{i=0}^\n{n-1}$. Here, the difficulty of the problem is defined by the number of variables $n$. We'll start by optimizing the small problem where $n=1$. Then, we\u2019ll apply transfer learning to optimize a larger problem where $n=3$, comparing the results with and without transfer learning to highlight the benefits.\n\nLet's begin by defining the run-functions for both the small-scale and large-scale problems:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import functools\n\nimport matplotlib.pyplot as plt\n\nfrom deephyper.analysis import figure_size\nfrom deephyper.analysis.hpo import plot_search_trajectory_single_objective_hpo\nfrom deephyper.evaluator import Evaluator\nfrom deephyper.evaluator.callback import TqdmCallback\nfrom deephyper.hpo import CBO, HpProblem\n\n\ndef run(config: dict, N: int) -> float:\n    # Definition of the function to minimize\n    y = sum([config[f\"x{i}\"] ** 2 for i in range(N)])\n    return -y  # Use the `-` sign to perform minimization\n\n\nn_small = 1\nn_large = 3\nrun_small = functools.partial(run, N=n_small)\nrun_large = functools.partial(run, N=n_large)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we can define the hyperparameter problem space based on $n$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "N = n_small\nproblem_small = HpProblem()\nfor i in range(N):\n    problem_small.add_hyperparameter((-10.0, 10.0), f\"x{i}\")\nproblem_small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "N = n_large\nproblem_large = HpProblem()\nfor i in range(N):\n    problem_large.add_hyperparameter((-10.0, 10.0), f\"x{i}\")\nproblem_large"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define setup the search and execute it:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = {}\nmax_evals = 100\nevaluator_small = Evaluator.create(\n    run_small, method=\"thread\", method_kwargs={\"callbacks\": [TqdmCallback()]}\n)\nsearch_small = CBO(problem_small, evaluator_small, random_state=42)\nresults_small = search_small.search(max_evals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "evaluator_large = Evaluator.create(\n    run_large, method=\"thread\", method_kwargs={\"callbacks\": [TqdmCallback()]}\n)\nsearch_large = CBO(problem_large, evaluator_large, random_state=42)\nresults[\"Large\"] = search_large.search(max_evals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "evaluator_large_tl = Evaluator.create(\n    run_large, method=\"thread\", method_kwargs={\"callbacks\": [TqdmCallback()]}\n)\nsearch_large_tl = CBO(problem_large, evaluator_large_tl, random_state=42)\nsearch_large_tl.fit_generative_model(results_small)\nresults[\"Large+TL\"] = search_large_tl.search(max_evals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we compare the results and quickly see that transfer-learning\nprovided a consequant speed-up for the search:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=figure_size(width=600))\n\nfor strategy, df in results.items():\n    plot_search_trajectory_single_objective_hpo(\n        df,\n        show_failures=False,\n        mode=\"min\",\n        ax=ax,\n        label=strategy,\n    )\n\nplt.xlabel(\"Time (sec.)\")\nplt.ylabel(\"Objective\")\nplt.yscale(\"log\")\nplt.grid(visible=True, which=\"minor\", linestyle=\":\")\nplt.grid(visible=True, which=\"major\", linestyle=\"-\")\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}