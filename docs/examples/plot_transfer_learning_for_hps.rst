
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/plot_transfer_learning_for_hps.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_examples_plot_transfer_learning_for_hps.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_plot_transfer_learning_for_hps.py:


Transfer Learning for Hyperparameter Search
===========================================

**Author(s)**: Romain Egele.

In this example we present how to apply transfer-learning for hyperparameter
search. Let's assume you have a bunch of similar tasks for example the search
of neural networks hyperparameters for different datasets. You can easily
imagine that close choices of hyperparameters can perform well these
different datasets even if some light additional tuning can help improve the
performance. Therefore, you can perform an expensive search once to then
reuse the explored set of hyperparameters of thid search and bias the
following search with it. Here, we will use a cheap to compute and easy to
understand example where we maximise the :math:`f(x) = -\sum_{i=0}^
{n-1}` function. In this case the size of the problem can be defined by the
variable :math:`n`. We will start by optimizing the small-size problem
where :math:`n=1`, then apply transfer-learning from to optimize the
larger-size problem where :math:`n=2` and visualize the difference if were
not to apply transfer-learning on this larger problem instance.

Let us start by defining the run-functions of the small and large scale problems:

.. GENERATED FROM PYTHON SOURCE LINES 27-44

.. code-block:: Python

    import functools
    import matplotlib.pyplot as plt

    from deephyper.hpo import HpProblem
    from deephyper.evaluator import Evaluator
    from deephyper.evaluator.callback import TqdmCallback
    from deephyper.hpo import CBO


    def run(config: dict, N: int) -> float:
        y = -sum([config[f"x{i}"] ** 2 for i in range(N)])
        return y


    run_small = functools.partial(run, N=1)
    run_large = functools.partial(run, N=2)








.. GENERATED FROM PYTHON SOURCE LINES 45-46

Then, we can define the hyperparameter problem space based on :math:`n`

.. GENERATED FROM PYTHON SOURCE LINES 46-53

.. code-block:: Python


    N = 1
    problem_small = HpProblem()
    for i in range(N):
        problem_small.add_hyperparameter((-10.0, 10.0), f"x{i}")
    problem_small





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Configuration space object:
      Hyperparameters:
        x0, Type: UniformFloat, Range: [-10.0, 10.0], Default: 0.0




.. GENERATED FROM PYTHON SOURCE LINES 54-61

.. code-block:: Python


    N = 2
    problem_large = HpProblem()
    for i in range(N):
        problem_large.add_hyperparameter((-10.0, 10.0), f"x{i}")
    problem_large





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Configuration space object:
      Hyperparameters:
        x0, Type: UniformFloat, Range: [-10.0, 10.0], Default: 0.0
        x1, Type: UniformFloat, Range: [-10.0, 10.0], Default: 0.0




.. GENERATED FROM PYTHON SOURCE LINES 62-63

Then, we define setup the search and execute it:

.. GENERATED FROM PYTHON SOURCE LINES 63-72

.. code-block:: Python


    results = {}
    max_evals = 20
    evaluator_small = Evaluator.create(
        run_small, method="thread", method_kwargs={"callbacks": [TqdmCallback()]}
    )
    search_small = CBO(problem_small, evaluator_small, random_state=42)
    results["Small"] = search_small.search(max_evals)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/20 [00:00<?, ?it/s]      5%|▌         | 1/20 [00:00<00:00, 47662.55it/s, failures=0, objective=-3.23]     10%|█         | 2/20 [00:00<00:00, 359.30it/s, failures=0, objective=-3.23]       15%|█▌        | 3/20 [00:00<00:00, 283.55it/s, failures=0, objective=-1.22]     20%|██        | 4/20 [00:00<00:00, 255.12it/s, failures=0, objective=-1.22]     25%|██▌       | 5/20 [00:00<00:00, 237.18it/s, failures=0, objective=-1.22]     30%|███       | 6/20 [00:00<00:00, 227.41it/s, failures=0, objective=-1.22]     35%|███▌      | 7/20 [00:00<00:00, 222.78it/s, failures=0, objective=-1.22]     40%|████      | 8/20 [00:00<00:00, 218.37it/s, failures=0, objective=-0.754]     45%|████▌     | 9/20 [00:00<00:00, 213.25it/s, failures=0, objective=-0.754]     50%|█████     | 10/20 [00:00<00:00, 210.69it/s, failures=0, objective=-0.754]     55%|█████▌    | 11/20 [00:00<00:00, 85.39it/s, failures=0, objective=-0.754]      55%|█████▌    | 11/20 [00:00<00:00, 85.39it/s, failures=0, objective=-0.754]     60%|██████    | 12/20 [00:00<00:00, 85.39it/s, failures=0, objective=-0.754]     65%|██████▌   | 13/20 [00:00<00:00, 85.39it/s, failures=0, objective=-0.26]      70%|███████   | 14/20 [00:00<00:00, 85.39it/s, failures=0, objective=-0.0145]     75%|███████▌  | 15/20 [00:00<00:00, 85.39it/s, failures=0, objective=-0.0145]     80%|████████  | 16/20 [00:00<00:00, 85.39it/s, failures=0, objective=-0.0145]     85%|████████▌ | 17/20 [00:00<00:00, 85.39it/s, failures=0, objective=-0.0145]     90%|█████████ | 18/20 [00:00<00:00, 85.39it/s, failures=0, objective=-0.0145]     95%|█████████▌| 19/20 [00:00<00:00, 85.39it/s, failures=0, objective=-0.00148]    100%|██████████| 20/20 [00:00<00:00, 20.50it/s, failures=0, objective=-0.00148]    100%|██████████| 20/20 [00:00<00:00, 20.50it/s, failures=0, objective=-0.000458]



.. GENERATED FROM PYTHON SOURCE LINES 73-80

.. code-block:: Python


    evaluator_large = Evaluator.create(
        run_large, method="thread", method_kwargs={"callbacks": [TqdmCallback()]}
    )
    search_large = CBO(problem_large, evaluator_large, random_state=42)
    results["Large"] = search_large.search(max_evals)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


      0%|          | 0/20 [00:00<?, ?it/s]
      5%|▌         | 1/20 [00:00<00:00, 45590.26it/s, failures=0, objective=-48.8]
     10%|█         | 2/20 [00:00<00:00, 223.64it/s, failures=0, objective=-40.3]  
     15%|█▌        | 3/20 [00:00<00:00, 163.81it/s, failures=0, objective=-40.3]
     20%|██        | 4/20 [00:00<00:00, 147.79it/s, failures=0, objective=-6.24]
     25%|██▌       | 5/20 [00:00<00:00, 139.82it/s, failures=0, objective=-6.24]
     30%|███       | 6/20 [00:00<00:00, 134.66it/s, failures=0, objective=-6.24]
     35%|███▌      | 7/20 [00:00<00:00, 131.51it/s, failures=0, objective=-6.24]
     40%|████      | 8/20 [00:00<00:00, 129.23it/s, failures=0, objective=-2.88]
     45%|████▌     | 9/20 [00:00<00:00, 126.87it/s, failures=0, objective=-2.88]
     50%|█████     | 10/20 [00:00<00:00, 125.59it/s, failures=0, objective=-2.88]
     55%|█████▌    | 11/20 [00:00<00:00, 68.20it/s, failures=0, objective=-2.88] 
     55%|█████▌    | 11/20 [00:00<00:00, 68.20it/s, failures=0, objective=-2.88]
     60%|██████    | 12/20 [00:00<00:00, 68.20it/s, failures=0, objective=-2.88]
     65%|██████▌   | 13/20 [00:00<00:00, 68.20it/s, failures=0, objective=-2.88]
     70%|███████   | 14/20 [00:00<00:00, 68.20it/s, failures=0, objective=-0.00379]
     75%|███████▌  | 15/20 [00:00<00:00, 68.20it/s, failures=0, objective=-0.00379]
     80%|████████  | 16/20 [00:00<00:00, 68.20it/s, failures=0, objective=-0.00379]
     85%|████████▌ | 17/20 [00:00<00:00, 68.20it/s, failures=0, objective=-0.00379]
     90%|█████████ | 18/20 [00:00<00:00, 20.37it/s, failures=0, objective=-0.00379]
     90%|█████████ | 18/20 [00:00<00:00, 20.37it/s, failures=0, objective=-0.00379]
     95%|█████████▌| 19/20 [00:00<00:00, 20.37it/s, failures=0, objective=-0.00379]
    100%|██████████| 20/20 [00:00<00:00, 20.37it/s, failures=0, objective=-0.00379]



.. GENERATED FROM PYTHON SOURCE LINES 81-89

.. code-block:: Python


    evaluator_large_tl = Evaluator.create(
        run_large, method="thread", method_kwargs={"callbacks": [TqdmCallback()]}
    )
    search_large_tl = CBO(problem_large, evaluator_large_tl, random_state=42)
    search_large_tl.fit_generative_model(results["Small"])
    results["Large+TL"] = search_large_tl.search(max_evals)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /Users/romainegele/miniforge3/envs/dh-3.12-240724/lib/python3.12/site-packages/rdt/transformers/utils.py:12: DeprecationWarning: module 'sre_parse' is deprecated
      import sre_parse  # isort:skip
    /Users/romainegele/Documents/Argonne/deephyper/deephyper/hpo/_cbo.py:744: UserWarning: The value of q=0.9 is replaced by q_max=0.5 because a minimum of 10 samples are required to perform transfer-learning!
      warnings.warn(
    /Users/romainegele/Documents/Argonne/deephyper/deephyper/hpo/_cbo.py:781: DeprecationWarning: Please use `space[name]`
      hp = self._problem.space.get_hyperparameter(hp_name)


      0%|          | 0/20 [00:00<?, ?it/s]

      5%|▌         | 1/20 [00:00<00:00, 26214.40it/s, failures=0, objective=-35.4]

     10%|█         | 2/20 [00:00<00:01, 13.81it/s, failures=0, objective=-35.4]   

     10%|█         | 2/20 [00:00<00:01, 13.81it/s, failures=0, objective=-23.9]

     15%|█▌        | 3/20 [00:00<00:01, 13.81it/s, failures=0, objective=-23.9]

     20%|██        | 4/20 [00:00<00:01,  8.58it/s, failures=0, objective=-23.9]

     20%|██        | 4/20 [00:00<00:01,  8.58it/s, failures=0, objective=-23.9]

     25%|██▌       | 5/20 [00:00<00:02,  6.05it/s, failures=0, objective=-23.9]

     25%|██▌       | 5/20 [00:00<00:02,  6.05it/s, failures=0, objective=-23.9]

     30%|███       | 6/20 [00:00<00:02,  6.26it/s, failures=0, objective=-23.9]

     30%|███       | 6/20 [00:00<00:02,  6.26it/s, failures=0, objective=-1.2] 

     35%|███▌      | 7/20 [00:01<00:02,  6.42it/s, failures=0, objective=-1.2]

     35%|███▌      | 7/20 [00:01<00:02,  6.42it/s, failures=0, objective=-0.967]

     40%|████      | 8/20 [00:01<00:01,  6.54it/s, failures=0, objective=-0.967]

     40%|████      | 8/20 [00:01<00:01,  6.54it/s, failures=0, objective=-0.967]

     45%|████▌     | 9/20 [00:01<00:01,  6.62it/s, failures=0, objective=-0.967]

     45%|████▌     | 9/20 [00:01<00:01,  6.62it/s, failures=0, objective=-0.967]

     50%|█████     | 10/20 [00:01<00:01,  6.67it/s, failures=0, objective=-0.967]

     50%|█████     | 10/20 [00:01<00:01,  6.67it/s, failures=0, objective=-0.967]

     55%|█████▌    | 11/20 [00:01<00:01,  5.78it/s, failures=0, objective=-0.967]

     55%|█████▌    | 11/20 [00:01<00:01,  5.78it/s, failures=0, objective=-0.967]

     60%|██████    | 12/20 [00:01<00:01,  5.30it/s, failures=0, objective=-0.967]

     60%|██████    | 12/20 [00:01<00:01,  5.30it/s, failures=0, objective=-0.4]  

     65%|██████▌   | 13/20 [00:02<00:01,  4.99it/s, failures=0, objective=-0.4]

     65%|██████▌   | 13/20 [00:02<00:01,  4.99it/s, failures=0, objective=-0.4]

     70%|███████   | 14/20 [00:02<00:01,  4.79it/s, failures=0, objective=-0.4]

     70%|███████   | 14/20 [00:02<00:01,  4.79it/s, failures=0, objective=-0.4]

     75%|███████▌  | 15/20 [00:02<00:01,  4.65it/s, failures=0, objective=-0.4]

     75%|███████▌  | 15/20 [00:02<00:01,  4.65it/s, failures=0, objective=-0.391]

     80%|████████  | 16/20 [00:02<00:00,  4.53it/s, failures=0, objective=-0.391]

     80%|████████  | 16/20 [00:02<00:00,  4.53it/s, failures=0, objective=-0.391]

     85%|████████▌ | 17/20 [00:03<00:00,  4.44it/s, failures=0, objective=-0.391]

     85%|████████▌ | 17/20 [00:03<00:00,  4.44it/s, failures=0, objective=-0.391]

     90%|█████████ | 18/20 [00:03<00:00,  4.38it/s, failures=0, objective=-0.391]

     90%|█████████ | 18/20 [00:03<00:00,  4.38it/s, failures=0, objective=-0.391]

     95%|█████████▌| 19/20 [00:03<00:00,  4.33it/s, failures=0, objective=-0.391]

     95%|█████████▌| 19/20 [00:03<00:00,  4.33it/s, failures=0, objective=-0.191]

    100%|██████████| 20/20 [00:03<00:00,  4.31it/s, failures=0, objective=-0.191]

    100%|██████████| 20/20 [00:03<00:00,  4.31it/s, failures=0, objective=-0.149]



.. GENERATED FROM PYTHON SOURCE LINES 90-92

Finally, we compare the results and quickly see that transfer-learning
provided a consequant speed-up for the search:

.. GENERATED FROM PYTHON SOURCE LINES 92-113

.. code-block:: Python


    # from deephyper.analysis import figure_size
    from deephyper.analysis.hpo import plot_search_trajectory_single_objective_hpo

    fig, ax = plt.subplots()

    for strategy, df in results.items():
        # x = [i for i in range(len(df))]
        # plt.scatter(x, df.objective, label=strategy, alpha=0.5)
        # plt.plot(x, df.objective.cummax(), alpha=0.5)
        plot_search_trajectory_single_objective_hpo(
            df, show_failures=False, ax=ax, label=strategy
        )


    plt.xlabel("Time (sec.)")
    plt.ylabel("Objective")
    plt.grid()
    plt.legend()
    plt.show()




.. image-sg:: /examples/images/sphx_glr_plot_transfer_learning_for_hps_001.png
   :alt: plot transfer learning for hps
   :srcset: /examples/images/sphx_glr_plot_transfer_learning_for_hps_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 8.913 seconds)


.. _sphx_glr_download_examples_plot_transfer_learning_for_hps.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_transfer_learning_for_hps.ipynb <plot_transfer_learning_for_hps.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_transfer_learning_for_hps.py <plot_transfer_learning_for_hps.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_transfer_learning_for_hps.zip <plot_transfer_learning_for_hps.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
